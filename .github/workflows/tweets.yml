name: Scrape Tweets to Supabase (All + Priority)

on:
  # run every hour; we'll gate by CET/CEST hour in the job
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:
    inputs:
      which_mode:
        description: 'Choose mode to run (all or priority)'
        required: false
        default: 'all'
      tweet_limit:
        description: 'Max tweets per user (optional)'
        required: false
        default: '100'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1) Checkout repository
      - uses: actions/checkout@v4

      # 2) Install R
      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3'

      # 3) System libraries for R packages that need compilation
      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends \
            build-essential libpq-dev libssl-dev \
            libcurl4-openssl-dev libxml2-dev \
            python3-dev python3-venv libpng-dev zlib1g-dev

      # 4) Python for reticulate / twscrape
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 5) Figure out CET/CEST hour for gating
      - id: cethour
        name: Get CET/CEST hour
        run: echo "hour=$(TZ=Europe/Paris date +%H)" >> $GITHUB_OUTPUT

      # 6a) Scheduled run — ALL handles at 04:00 CET/CEST
      - name: Run scraper (ALL @ 04:00 CET/CEST)
        if: ${{ github.event_name == 'schedule' && steps.cethour.outputs.hour == '04' }}
        env:
          # ---- Supabase (secrets) ----
          SUPABASE_HOST:   ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT:   ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DB:     ${{ secrets.SUPABASE_DB }}
          SUPABASE_USER:   ${{ secrets.SUPABASE_USER }}
          SUPABASE_PWD:    ${{ secrets.SUPABASE_PWD }}
          # ---- Twitter cookies (secret) ----
          TW_COOKIES_JSON: ${{ secrets.TW_COOKIES_JSON }}
          # ---- Handles (repo variable or leave default in R) ----
          TW_HANDLES:      ${{ vars.TW_HANDLES }}
          # ---- Priority list (repo variable or leave default in R) ----
          TW_PRIORITY_HANDLES: ${{ vars.TW_PRIORITY_HANDLES }}
          # ---- R script controls ----
          SCRAPE_MODE:     "all"
          TWEET_LIMIT:     "100"
          PY_VENV_PATH:    ".venv"
        run: Rscript fetch_twitter_to_supabase.R

      # 6b) Scheduled run — PRIORITY handles at 13:00 CET/CEST
      - name: Run scraper (PRIORITY @ 13:00 CET/CEST)
        if: ${{ github.event_name == 'schedule' && steps.cethour.outputs.hour == '13' }}
        env:
          SUPABASE_HOST:   ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT:   ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DB:     ${{ secrets.SUPABASE_DB }}
          SUPABASE_USER:   ${{ secrets.SUPABASE_USER }}
          SUPABASE_PWD:    ${{ secrets.SUPABASE_PWD }}
          TW_COOKIES_JSON: ${{ secrets.TW_COOKIES_JSON }}
          TW_HANDLES:      ${{ vars.TW_HANDLES }}
          TW_PRIORITY_HANDLES: ${{ vars.TW_PRIORITY_HANDLES }}
          SCRAPE_MODE:     "priority"
          TWEET_LIMIT:     "100"
          PY_VENV_PATH:    ".venv"
        run: Rscript fetch_twitter_to_supabase.R

      # 6c) Manual run — choose mode from the UI
      - name: Run scraper (manual)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        env:
          SUPABASE_HOST:   ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT:   ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DB:     ${{ secrets.SUPABASE_DB }}
          SUPABASE_USER:   ${{ secrets.SUPABASE_USER }}
          SUPABASE_PWD:    ${{ secrets.SUPABASE_PWD }}
          TW_COOKIES_JSON: ${{ secrets.TW_COOKIES_JSON }}
          TW_HANDLES:      ${{ vars.TW_HANDLES }}
          TW_PRIORITY_HANDLES: ${{ vars.TW_PRIORITY_HANDLES }}
          SCRAPE_MODE:     ${{ inputs.which_mode }}
          TWEET_LIMIT:     ${{ inputs.tweet_limit }}
          PY_VENV_PATH:    ".venv"
        run: Rscript fetch_twitter_to_supabase.R
