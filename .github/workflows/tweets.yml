name: Scrape Tweets to Supabase (All + Priority)

on:
  schedule:
    - cron: '0 * * * *'   # hourly; we gate inside
  workflow_dispatch:
    inputs:
      which_mode:
        description: 'Choose mode to run (all or priority)'
        required: false
        default: 'all'
      tweet_limit:
        description: 'Max tweets per user (optional)'
        required: false
        default: '100'

concurrency:
  group: scrape-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # 0) Time/mode gate
  gate:
    runs-on: ubuntu-latest
    outputs:
      which: ${{ steps.pick.outputs.which }}   # 'all' | 'priority' | 'none'
    steps:
      - id: pick
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            # Pass through the manual choice so ONLY the scrape job runs
            echo "which=${{ inputs.which_mode }}" >> "$GITHUB_OUTPUT"
          else
            HOUR=$(TZ=Europe/Paris date +%H)
            if [ "$HOUR" = "04" ]; then
              echo "which=all" >> "$GITHUB_OUTPUT"
            elif [ "$HOUR" = "13" ]; then
              echo "which=priority" >> "$GITHUB_OUTPUT"
            else
              echo "which=none" >> "$GITHUB_OUTPUT"
            fi
          fi

  # 1) Scrape only once (no separate manual job)
  scrape:
    needs: gate
    if: ${{ needs.gate.outputs.which == 'all' || needs.gate.outputs.which == 'priority' }}
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3'

      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends \
            build-essential libpq-dev libssl-dev \
            libcurl4-openssl-dev libxml2-dev \
            python3-dev python3-venv libpng-dev zlib1g-dev

      - uses: actions/setup-python@v6
        with:
          python-version: '3.11'

      - name: Run scraper
        env:
          # Supabase
          SUPABASE_HOST:   ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT:   ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DB:     ${{ secrets.SUPABASE_DB }}
          SUPABASE_USER:   ${{ secrets.SUPABASE_USER }}
          SUPABASE_PWD:    ${{ secrets.SUPABASE_PWD }}
          # Cookies
          TW_COOKIES_JSON: ${{ secrets.TW_COOKIES_JSON }}
          # Lists (repo variables)
          TW_HANDLES:           ${{ vars.TW_HANDLES }}
          TW_PRIORITY_HANDLES:  ${{ vars.TW_PRIORITY_HANDLES }}
          # Mode & limits
          SCRAPE_MODE:          ${{ needs.gate.outputs.which }}   # all | priority
          TWEET_LIMIT:          ${{ inputs.tweet_limit || '100' }}
          PY_VENV_PATH: ".venv"
        run: Rscript fetch_twitter_to_supabase.R
